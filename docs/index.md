A project demonstrating the implementation of a trustworthy AI system.

-   showing how following software engineering best practices supports compliance
-   provide an exemplary system architecture for a trustworthy AI system
-   provide explicit implementations of software components
-   link engineering practices and software components to the the requirements for high-risk system under the AI Act

!!! warning "TODO"

    Out of scope:

    - legal advice
    - all-encompassing reference architecture
    - LLMs
    - GPAI-specific requirements under Chapter V (roadmap?), maybe link to AI Office [Code of Practice](https://digital-strategy.ec.europa.eu/en/policies/ai-code-practice)
    - machine learning theory and best practice (algorithm and software design), link beyond jupyter?

## Intended Audiences

This project is intended for AI practitioners, data scientists, and engineers who are interested in implementing trustworthy AI systems under the European AI Act.

## Recommended Knowledge

-   A basic understanding of machine learning and AI concepts
-   Familiarity with Python programming
-   An understanding of the terminology in |Art. 3| of the AI Act
-   Software engineering best practices for ML:
    -   See the [Beyond Jupyter series](https://transferlab.ai/trainings/beyond-jupyter/) for an introduction
